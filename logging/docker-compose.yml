version: '3.7'

services:

  fix-file-permissions:
    image: alpine
    hostname: fix-file-permissions
    command: >
      sh -c "chown 1000 /usr/share/elasticsearch/data &&
             chgrp 1000 /usr/share/elasticsearch/data &&
             chown 1000 /usr/share/elasticsearch/data/lost\+found &&
             chgrp 1000 /usr/share/elasticsearch/data/lost\+found &&
             echo File Permissions changed"
    volumes:
    - elasticsearch-data:/usr/share/elasticsearch/data
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: none

  elasticsearch:
    hostname: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELK_VERSION:-6.5.0}
    environment:
    #    - xpack.security.enabled=false
    - http.host=0.0.0.0
    - transport.host=127.0.0.1
    - bootstrap.memory_lock=true
    - "ES_JAVA_OPTS=-Xms${ES_JVM_HEAP:-1024m} -Xmx${ES_JVM_HEAP:-1024m}"
    ports:
    - "9200:9200"
    - "9300:9300"
    configs:
    - source: elastic_config
      target: /usr/share/elasticsearch/config/elasticsearch.yml
    networks:
    - logging
    - proxy
    volumes:
    - elasticsearch-data:/usr/share/elasticsearch/data
    depends_on:
    - fix-file-permissions
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.httpsOnly=true
      - com.df.serviceDomain=elasticsearch.${DOMAIN_NAME:-docker.usc.edu}
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s
      resources:
        reservations:
          memory: ${ES_MEM_LIMIT:-2g}
        limits:
          memory: ${ES_MEM_LIMIT:-2g}
    #Healthcheck to confirm availability of ES. Other containers wait on this.
    healthcheck:
      test: ["CMD", "curl","-s" ,"-f", "-u", "elastic:${ES_PASSWORD:-changeme}", "http://localhost:9200/_cat/health"]

  logstash:
    image: docker.elastic.co/logstash/logstash:${ELK_VERSION:-6.5.0}
    ports:
    - "5000:5000"
    - "9600:9600"
    configs:
    - source: logstash_config
      target: /usr/share/logstash/config/logstash.yml
    - source: logstash_pipeline
      target: /usr/share/logstash/pipeline/logstash.conf
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
      LOGSPOUT: ignore
    networks:
    - logging
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s
      resources:
        reservations:
          memory: 400M
        limits:
          memory: 600M

  kibana:
    image: docker.elastic.co/kibana/kibana:${ELK_VERSION:-6.5.0}
    ports:
    - "5601:5601"
    environment:
    #    - xpack.security.enabled=false
    - "ELASTICSEARCH_PASSWORD=${ES_PASSWORD:-changeme}"
    - ELASTICSEARCH_URL=http://elasticsearch:9200
    configs:
    - source: kibana_config
      target: /usr/share/kibana/config/kibana.yml
    networks:
    - logging
    - proxy
    #We don't start Kibana until the ES instance is ready
    depends_on:
    - elasticsearch
    healthcheck:
      test: ["CMD", "curl", "-s", "-f", "http://localhost:5601/login"]
      retries: 6
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.serviceDomain.1=${ELK_SUB_DOMAIN:-elk}.${DOMAIN_NAME:-docker.usc.edu}
      - com.df.port.1=5601
      - com.df.xForwardedProto.1=true
      - com.df.httpsOnly.1=true
      - com.df.servicePath.2=${ELK_PATH:-/elk}
      - com.df.port.2=5601
      - com.df.reqPathSearchReplace.2=${ELK_PATH:-/elk},/
      - com.df.xForwardedProto.2=true
      - com.df.httpsOnly.2=true
      - com.df.serviceDomain.3=${KIBANA_SUB_DOMAIN:-kibana}.${DOMAIN_NAME:-docker.usc.edu}
      - com.df.port.3=5601
      - com.df.xForwardedProto.3=true
      - com.df.httpsOnly.3=true
      - com.df.servicePath.4=${KIBANA_PATH:-/kibana}
      - com.df.port.4=5601
      - com.df.reqPathSearchReplace.4=${KIBANA_PATH:-/kibana},/
      - com.df.xForwardedProto.4=true
      - com.df.httpsOnly.4=true
      #      - com.df.servicePath=/app,/elasticsearch,/api,/ui,/bundles,/plugins,/status,/es_admin
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s
      resources:
        reservations:
          memory: 256m
        limits:
          memory: 512m

  logspout:
    image: gliderlabs/logspout:${LOGSPOUT_VERSION:-v3.2.2}
    networks:
    - logging
    environment:
      ROUTE_URIS: syslog://logstash:51415
      #       ROUTE_URIS: logstash://logstash:5000
      LOGSTASH_TAGS: docker-elk
      SYSLOG_FORMAT: rfc3164
    depends_on:
    - logstash
    volumes:
    - /etc/hostname:/etc/host_hostname:ro
    - /var/run/docker.sock:/var/run/docker.sock:ro
    command:
      syslog://logstash:51415
    #      logstash://logstash:5000
    deploy:
      mode: global
      resources:
        limits:
          cpus: '0.20'
          memory: 256M
        reservations:
          cpus: '0.10'
          memory: 128M
      restart_policy:
        condition: on-failure
      labels:
      - com.df.notify=true
      - com.df.distribute=true
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

#  #Configure Stack container. This short lived container configures the stack once Kibana and Elasticsearch are available. More specifically, using a script it sets passwords, import dashboards, sets a default index pattern, loads templates and pipelines
#  configure_stack:
#    #    container_name: configure_stack
#    image: docker.elastic.co/beats/metricbeat:${ELASTIC_VERSION:-6.5.0}
#    configs:
#    - source: configure-stack
#      target: /usr/local/bin/configure-stack.sh
#    #      read-only
#    - source: pipelines
#      target: /usr/local/bin/pipelines/docker-logs.json
#    - source: templates
#      target: /usr/local/bin/templates/docker-logs.json
#    #    volumes: ['./init/configure-stack.sh:/usr/local/bin/configure-stack.sh:ro','./init/pipelines/:/usr/local/bin/pipelines/','./init/templates/:/usr/local/bin/templates/']
#    command: ['/bin/bash', '-c', 'cat /usr/local/bin/configure-stack.sh | tr -d "\r" | bash']
#    networks:
#    - logging
#    environment: ['ELASTIC_VERSION=${ELASTIC_VERSION:-6.5.0}','ES_PASSWORD=${ES_PASSWORD:-changeme}','DEFAULT_INDEX_PATTERN=${DEFAULT_INDEX_PATTERN:-metricbeat-*}']
#    depends_on:
#    - elasticsearch
#    - kibana
#    deploy:
#      replicas: 1
#      update_config:
#        parallelism: 1
#        delay: 10s
#      restart_policy:
#        condition: none

volumes:
  elasticsearch-data:
    external: true

configs:
  elastic_config:
    file: ./config/elasticsearch/config/elasticsearch.yml
  logstash_config:
    file: ./config/logstash/config/logstash.yml
  logstash_pipeline:
    file: ./config/logstash/pipeline/logstash.conf
  kibana_config:
    file: ./config/kibana/config/kibana.yml
  configure-stack:
    file: ./config/init/configure-stack.sh
  pipelines:
    file: ./config/init/pipelines/docker-logs.json
  templates:
    file: ./config/init/templates/docker-logs.json
  heartbeat_config:
    file: ./config/beats/heartbeat/heartbeat.yml
  filebeat_config:
    file: ./config/beats/filebeat/filebeat.yml
  prospectors_config:
    file: ./config/beats/filebeat/prospectors.d/docker.yml
  packetbeat_config:
    file: ./config/beats/packetbeat/packetbeat.yml
  metricbeat_config:
    file: ./config/beats/metricbeat/metricbeat.yml
  metricbeat_docker_config:
    file: ./config/beats/metricbeat/modules.d/docker.yml
  metricbeat_system_config:
    file: ./config/beats/metricbeat/modules.d/system.yml

networks:
  logging:
    #    driver: overlay
    external: true
  proxy:
    external: true
